{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import moving MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving_MNIST = np.load('data/mnist_test_seq.npy')\n",
    "Moving_MNIST = Moving_MNIST / 255\n",
    "Moving_MNIST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give `torch` the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making into PyTorch tensor\n",
    "Moving_MNIST_tensor = torch.from_numpy(Moving_MNIST)\n",
    "\n",
    "# Putting the existing dimensions into appropriate order\n",
    "Moving_MNIST_tensor = Moving_MNIST_tensor.permute(1, 0, 2, 3)\n",
    "\n",
    "# Added the acknowledge that this is 1 spectral band\n",
    "Moving_MNIST_tensor = Moving_MNIST_tensor.unsqueeze(2)\n",
    "\n",
    "# Checking shape\n",
    "Moving_MNIST_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(range(10000), size = 8000, replace = False)\n",
    "\n",
    "OutofSample_indices = [index for index in range(10000) if index not in train_indices.tolist()]\n",
    "validation_indices = np.random.choice(OutofSample_indices, size = 1000, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating $x$ (first $10$ in each sequence) and $y$ (last $10$ in each sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_x_y(tensor_to_separate):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(tensor_to_separate)):\n",
    "        current_seq = tensor_to_separate[i, :, :, :, :]\n",
    "        for j in range(current_seq.shape[0]):\n",
    "            if j >= 10:\n",
    "                current_x = current_seq[(j-10):j].numpy()\n",
    "                x.append(current_x)\n",
    "                current_y = current_seq[j].unsqueeze(dim = 0).numpy()\n",
    "                y.append(current_y)\n",
    "    x = np.asarray(x)\n",
    "    x = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "    y = np.asarray(y)\n",
    "    y = torch.from_numpy(y).type(torch.FloatTensor)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sep_x_y(Moving_MNIST_tensor[train_indices])\n",
    "x_validation, y_validation = sep_x_y(Moving_MNIST_tensor[validation_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the overlaid $(x, y)$ sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.choice(len(x_validation))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(x_validation[random_index, i, 0], alpha = 0.25, cmap = 'gist_gray')\n",
    "plt.imshow(y_validation[random_index, 0, 0], cmap = 'Reds', alpha = 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTime_LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias, GPU):\n",
    "        \"\"\"\n",
    "        Initialize ConvTime_LSTM cell.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size: (int, int)\n",
    "            Height and width of input tensor as (height, width).\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvTime_LSTMCell, self).__init__()\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        self.GPU         = GPU\n",
    "        \n",
    "        ## Defining the input convolutional layer ##\n",
    "        self.i_conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                                out_channels=self.hidden_dim,\n",
    "                                kernel_size=self.kernel_size,\n",
    "                                padding=self.padding,\n",
    "                                bias=self.bias)\n",
    "        \n",
    "        ## Defining the T2 convolutional layer ##\n",
    "        self.T1_conv_x = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                   out_channels=self.hidden_dim,\n",
    "                                   kernel_size=self.kernel_size,\n",
    "                                   padding=self.padding,\n",
    "                                   bias=self.bias)\n",
    "        self.T1_conv_t = nn.Conv2d(in_channels=1,\n",
    "                                   out_channels=self.hidden_dim,\n",
    "                                   kernel_size=self.kernel_size,\n",
    "                                   padding=self.padding,\n",
    "                                   bias=self.bias)\n",
    "        \n",
    "        ## Defining the T1 convolutional layer ##\n",
    "        self.T2_conv_x = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                   out_channels=self.hidden_dim,\n",
    "                                   kernel_size=self.kernel_size,\n",
    "                                   padding=self.padding,\n",
    "                                   bias=self.bias)\n",
    "        self.T2_conv_t = nn.Conv2d(in_channels=1,\n",
    "                                   out_channels=self.hidden_dim,\n",
    "                                   kernel_size=self.kernel_size,\n",
    "                                   padding=self.padding,\n",
    "                                   bias=self.bias)\n",
    "        \n",
    "        ## Defining the activation convolutional layer ##\n",
    "        self.c_conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                                out_channels=self.hidden_dim,\n",
    "                                kernel_size=self.kernel_size,\n",
    "                                padding=self.padding,\n",
    "                                bias=self.bias)\n",
    "        \n",
    "        ## Defining the output convolutional layer ##\n",
    "        self.o_conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim + 1,\n",
    "                                out_channels=self.hidden_dim,\n",
    "                                kernel_size=self.kernel_size,\n",
    "                                padding=self.padding,\n",
    "                                bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, time_tensor, cur_state):\n",
    "        \n",
    "        \n",
    "        ## Getting the h_{m-1} and c_{m-1} ##\n",
    "        ##     the previous hidden and activations ##\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "\n",
    "        ## concatenate the prev. hidden state and the current input along the color channel dim ##\n",
    "        x_h_combined = torch.cat([input_tensor, h_cur], dim = 1)\n",
    "        x_h_t_combined = torch.cat([input_tensor, h_cur, time_tensor], dim = 1)\n",
    "        \n",
    "        \n",
    "        ## The input gate ##\n",
    "        ## Running the input convolution ##\n",
    "        i_conv_outputs = self.i_conv(x_h_combined)\n",
    "        ## Running the input LSTM gate equations ##\n",
    "        i_m = torch.sigmoid(i_conv_outputs)\n",
    "        \n",
    "        \n",
    "        ## The first time gate ##\n",
    "        ## Running the first time convolution for x ##\n",
    "        T1_x_conv_output = self.T1_conv_x(input_tensor)\n",
    "        ## Running the first time convolution for t ##\n",
    "        ## Ensuring that the theoretical constraint of non-positive is met ##\n",
    "        self.T1_conv_t.weight = torch.nn.Parameter(self.T1_conv_t.weight.clamp(max = 0))\n",
    "        ## Passing the convolution ##\n",
    "        T1_t_conv_output = self.T1_conv_t(time_tensor)\n",
    "        ## Performing the internally nested non-linearity ##\n",
    "        T1_t_conv_output = torch.sigmoid(T1_t_conv_output)\n",
    "        ## Consolidating the output of image and time ##\n",
    "        T1_conv_outputs = T1_t_conv_output + T1_x_conv_output\n",
    "        ## Performing the externally nested non-linearity ##\n",
    "        T1_m = torch.sigmoid(T1_conv_outputs)\n",
    "        \n",
    "        \n",
    "        ## The second time gate ##\n",
    "        ## Running the second time convolution for x ##\n",
    "        T2_x_conv_output = self.T2_conv_x(input_tensor)\n",
    "        ## Running the first time convolution for t ##\n",
    "        ## Passing the convolution ##\n",
    "        T2_t_conv_output = self.T2_conv_t(time_tensor)\n",
    "        ## Performing the internally nested non-linearity ##\n",
    "        T2_t_conv_output = torch.sigmoid(T2_t_conv_output)\n",
    "        ## Consolidating the output of image and time ##\n",
    "        T2_conv_outputs = T2_t_conv_output + T2_x_conv_output\n",
    "        ## Performing the externally nested non-linearity ##\n",
    "        T2_m = torch.sigmoid(T2_conv_outputs)\n",
    "        \n",
    "        \n",
    "        ## The c vectors ##\n",
    "        ## Running the c convolution ##\n",
    "        c_conv_outputs = self.c_conv(x_h_combined)\n",
    "        ## Computing the c tilde and c activation vectors ##\n",
    "        c_m_tilde = (((1 - i_m * T1_m) * c_cur) +\n",
    "                     (i_m * T1_m * torch.tanh(c_conv_outputs)))\n",
    "        c_m = (((1 - i_m) * c_cur) +\n",
    "               (i_m * T2_m * torch.tanh(c_conv_outputs)))\n",
    "        \n",
    "         \n",
    "        ## The output gate ##\n",
    "        ## Running the output gate convolution ##\n",
    "        o_conv_output = self.o_conv(x_h_t_combined)\n",
    "        ## Running the output LSTM gate equations ##\n",
    "        o_m = torch.sigmoid(o_conv_output)\n",
    "        \n",
    "        \n",
    "        ## The hidden vector ##\n",
    "        h_m = o_m * torch.tanh(c_m_tilde)\n",
    "        \n",
    "        \n",
    "        return h_m, c_m\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        to_return = (Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)),\n",
    "                     Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)))\n",
    "        if self.GPU:\n",
    "            to_return = (to_return[0].cuda(), to_return[1].cuda())\n",
    "        return(to_return)\n",
    "\n",
    "\n",
    "class ConvTime_LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first, bias, return_all_layers, GPU):\n",
    "        super(ConvTime_LSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim  = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.GPU = GPU\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
    "\n",
    "            cell_list.append(ConvTime_LSTMCell(input_size=(self.height, self.width),\n",
    "                                               input_dim=cur_input_dim,\n",
    "                                               hidden_dim=self.hidden_dim[i],\n",
    "                                               kernel_size=self.kernel_size[i],\n",
    "                                               bias=self.bias,\n",
    "                                               GPU=self.GPU))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, time_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo \n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            hidden_state = self._init_hidden(batch_size=input_tensor.size(0))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list   = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "        cur_time_input = time_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "\n",
    "                h, c = self.cell_list[layer_idx](input_tensor = cur_layer_input[:, t, :, :, :],\n",
    "                                                 time_tensor = cur_time_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list   = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                    (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking one of the like-sequence tensors within the list to set parameters\n",
    "channels = x.shape[2]\n",
    "height = x.shape[3]\n",
    "width = x.shape[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_time_lstm = ConvTime_LSTM(input_size = (height,\n",
    "                                             width),\n",
    "                               input_dim = channels,\n",
    "                               hidden_dim = [128, 64, 64, 1],\n",
    "                               kernel_size = (5, 5),\n",
    "                               num_layers = 4,\n",
    "                               batch_first = True,\n",
    "                               bias = True,\n",
    "                               return_all_layers = False,\n",
    "                               GPU = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_time_lstm.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(conv_time_lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_indices):\n",
    "        'Initialization'\n",
    "        self.data_indices = data_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data_indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        IDs = self.data_indices[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        curr_x = x[IDs, :, :, :, :]\n",
    "        curr_y = y[IDs, :, :, :, :]\n",
    "\n",
    "        #return X, y\n",
    "        return(curr_x, curr_y)\n",
    "    \n",
    "class validation_Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_indices):\n",
    "        'Initialization'\n",
    "        self.data_indices = data_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data_indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        IDs = self.data_indices[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        curr_x = x_validation[IDs, :, :, :, :]\n",
    "        curr_y = y_validation[IDs, :, :, :, :]\n",
    "\n",
    "        #return X, y\n",
    "        return(curr_x, curr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_Dataset(data_indices=range(y.shape[0]))\n",
    "validation_set = validation_Dataset(data_indices=range(y_validation.shape[0]))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = training_set,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = validation_set,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_time_lstm = torch.nn.DataParallel(conv_time_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "epochs = int(np.ceil((7*10**5) / x.shape[0]))\n",
    "for i in range(epochs):\n",
    "    for data in train_loader:\n",
    "        \n",
    "        # data loader\n",
    "        batch_x, batch_y = data\n",
    "        \n",
    "        # move to GPU\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # run model and get the prediction\n",
    "        batch_y_hat = conv_time_lstm(batch_x,\n",
    "                                     torch.ones_like(batch_x) / 10)\n",
    "        batch_y_hat = batch_y_hat[0][0][:, -2:-1, :, :, :]\n",
    "        \n",
    "        # calculate and store the loss\n",
    "        batch_loss = loss(batch_y, batch_y_hat)\n",
    "        loss_list.append(batch_loss.item())\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch: ', i, '\\n\\tBatch loss: ', batch_loss.item(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list,\n",
    "         color = 'cyan',\n",
    "         label = 'Batch')\n",
    "plt.plot(np.convolve(loss_list, 1/10*np.ones(10))[10:-10],\n",
    "         color = 'navy',\n",
    "         label = 'Running average')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting random predictions for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_x, rand_y = next(iter(validation_loader))\n",
    "\n",
    "rand_y_hat = conv_time_lstm(rand_x.to(device),\n",
    "                            torch.ones_like(rand_x).to(device) / 10)[0][0][:, -2:-1, :, :, :]\n",
    "rand_y_hat = rand_y_hat.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing random predictions for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_validation_pred():\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    f.set_figheight(4)\n",
    "    f.set_figwidth(8)\n",
    "    random_index = np.random.choice(len(rand_x))\n",
    "    for i in range(10):\n",
    "        axarr[0].imshow(rand_x[random_index, i, 0], alpha = 0.25, cmap = 'gist_gray')\n",
    "        axarr[1].imshow(rand_x[random_index, i, 0], alpha = 0.25, cmap = 'gist_gray')\n",
    "    axarr[0].imshow(rand_y[random_index, 0, 0], cmap = 'Reds', alpha = 0.5)\n",
    "    axarr[0].set_title('Red = True', fontsize = 15)\n",
    "    axarr[1].imshow(rand_y_hat[random_index, 0, 0], cmap = 'Greens', alpha = 0.5)\n",
    "    axarr[1].set_title('Green = Predicted', fontsize = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_validation_pred()\n",
    "plot_random_validation_pred()\n",
    "plot_random_validation_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_pred_true():\n",
    "    random_index = np.random.choice(len(rand_x))\n",
    "    plt.imshow(rand_y[random_index, 0, 0], cmap = 'Reds', alpha = 0.5)\n",
    "    plt.imshow(rand_y_hat[random_index, 0, 0], cmap = 'Greens', alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_pred_true()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mimicking sequence-to-sequence by shuffling in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_index = np.random.choice(len(rand_x) - 1)\n",
    "rand_x = rand_x[random_index:(random_index+1)]\n",
    "\n",
    "for i in range(10):\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    f.set_figheight(3)\n",
    "    f.set_figwidth(6)\n",
    "    axarr[0].imshow(rand_x[0, 0, 0], cmap = 'gist_gray')\n",
    "    rand_y_hat = conv_time_lstm(rand_x.to(device),\n",
    "                                torch.ones_like(rand_x.to(device)) / 10)[0][0][:, -2:-1, :, :, :]\n",
    "    axarr[1].imshow(rand_y_hat[0, 0, 0].data.cpu().numpy(), cmap = 'Greens')\n",
    "    rand_x = torch.cat([rand_x, rand_y_hat.data.cpu()], dim = 1)\n",
    "    rand_x = rand_x[:, 1:]\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model weights for transfer learning to MissingMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(conv_time_lstm, 'ConvTimeLSTMSavedModel2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
